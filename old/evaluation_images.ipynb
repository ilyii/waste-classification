{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from SSWQ import SSWQ_V1\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device}: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_images_path = 'D:\\data_waste-classification\\evaluation\\sample_images\\\\'\n",
    "data_path = \"D:\\data_waste-classification\\evaluation\\evaluation_images\\\\\"\n",
    "#models_path = \"D:\\data_waste-classification\\evaluation\\models_woi\\\\\"\n",
    "models_path = \"D:\\data_waste-classification\\evaluation\\models_wi\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for file in os.listdir(sample_images_path):\n",
    "        images.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image = []\n",
    "labels = []\n",
    "\n",
    "for file in os.listdir(data_path):\n",
    "    if file == 'glas':\n",
    "        for c in os.listdir(os.path.join(data_path, file)):\n",
    "            image.append(c)\n",
    "            labels.append('glas')\n",
    "    if file == 'organic':\n",
    "        for c in os.listdir(os.path.join(data_path, file)):\n",
    "            image.append(c)\n",
    "            labels.append('organic')\n",
    "    if file == 'paper':\n",
    "        for c in os.listdir(os.path.join(data_path, file)):\n",
    "            image.append(c)\n",
    "            labels.append('paper')\n",
    "    if file == 'restmuell':\n",
    "        for c in os.listdir(os.path.join(data_path, file)):\n",
    "            image.append(c)\n",
    "            labels.append('restmuell')\n",
    "    if file == 'wertstoff':\n",
    "        for c in os.listdir(os.path.join(data_path, file)):\n",
    "            image.append(c)\n",
    "            labels.append('wertstoff')\n",
    "\n",
    "data = {'Images': image, 'labels': labels}\n",
    "data = pd.DataFrame(data)\n",
    "lb = LabelEncoder()\n",
    "data['encoded_labels'] = lb.fit_transform(data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "waste_types = {0: 'glas', 1: 'organic', 2: 'paper', 3: 'restmuell', 4: 'wertstoff'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose(\n",
    "    [transforms.Resize((256,256), interpolation= transforms.InterpolationMode.BICUBIC),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class GarbageDataset(Dataset):\n",
    "    def __init__(self, img_data, img_path, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.transform = transform\n",
    "        self.img_data = img_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = os.path.join(self.img_path, self.img_data.iloc[index].labels, self.img_data.iloc[index].Images)\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = torch.tensor(self.img_data.iloc[index].encoded_labels)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = GarbageDataset(data, data_path, transform_val)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "sample_img = list()\n",
    "labels = list(\"\" for _ in range(25))\n",
    "encoded_labels = list(0 for _ in range(25))\n",
    "for file in os.listdir(sample_images_path):\n",
    "        sample_img.append(file)\n",
    "sample_data = {'Images': sample_img, 'labels': labels, 'encoded_labels': encoded_labels}\n",
    "sample_dataset = pd.DataFrame(sample_data)\n",
    "sample_dataset = GarbageDataset(sample_dataset, sample_images_path, transform_val)\n",
    "sample_dataloader = DataLoader(sample_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def img_display(img):\n",
    "    MEAN = torch.tensor([0.485, 0.456, 0.406])\n",
    "    STD = torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "    img = img * STD[:, None, None] + MEAN[:, None, None]\n",
    "    npimg = img.numpy()\n",
    "    npimg = np.transpose(npimg, (1, 2, 0))\n",
    "    return npimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    _, pred = torch.max(out, dim=1)\n",
    "    return torch.sum(pred == labels).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.255]\n",
    "MEAN = torch.tensor(mean)\n",
    "STD = torch.tensor(std)\n",
    "mean50 = [0.5, 0.5, 0.5]\n",
    "std50 = [0.5, 0.5, 0.5]\n",
    "MEAN50 = torch.tensor(mean)\n",
    "STD50 = torch.tensor(std)\n",
    "\n",
    "transform_mean_std_50 = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean, std)]\n",
    ")\n",
    "transform_mean_std_other = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean, std)]\n",
    ")\n",
    "def img_display(img):\n",
    "    img = img * STD[:, None, None] + MEAN[:, None, None]\n",
    "    #img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    npimg = np.transpose(npimg, (1, 2, 0))\n",
    "    return npimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def editModel(model, path, classes):\n",
    "    if model == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=False)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, classes)\n",
    "        model.fc = model.fc.cuda()\n",
    "    if model == \"VGG16\":\n",
    "        model = models.vgg16(pretrained=False)\n",
    "        in_features = model.classifier[0].in_features\n",
    "        model.classifier = nn.Linear(in_features, classes)\n",
    "    if model == \"efficientnet-b3\" or model == \"efficientnet-b4\":\n",
    "        model = EfficientNet.from_pretrained(model,num_classes=classes)\n",
    "    if model == \"SSWQV1\":\n",
    "        model = SSWQ_V1(num_classes=classes, dropout=0.5, hidden_layer1=512, hidden_layer2=2048)\n",
    "\n",
    "    model.load_state_dict(torch.load(models_path+path, map_location='cuda:0'))\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "model1 = {\n",
    "    'name': \"VGG16\",\n",
    "    \"model\": editModel(\"VGG16\", \"vgg16.pt\", 5),\n",
    "    \"transform\": transform_mean_std_other,\n",
    "    \"resize\": (256, 256)\n",
    "}\n",
    "model2 = {\n",
    "    'name': \"resnet50\",\n",
    "    \"model\": editModel(\"resnet50\", \"resnet50.pt\", 5),\n",
    "    \"transform\": transform_mean_std_other,\n",
    "    \"resize\": (256, 256)\n",
    "}\n",
    "model3 = {\n",
    "    'name': \"eff_b3\",\n",
    "    \"model\": editModel(\"efficientnet-b3\", \"eff_b3.pt\", 5),\n",
    "    \"transform\": transform_mean_std_other,\n",
    "    \"resize\": (256, 256)\n",
    "}\n",
    "model4 = {\n",
    "    'name': \"eff_b4\",\n",
    "    \"model\": editModel(\"efficientnet-b4\", \"eff_b4.pt\", 5),\n",
    "    \"transform\": transform_mean_std_other,\n",
    "    \"resize\": (256, 256)\n",
    "}\n",
    "model5 = {\n",
    "    'name': \"SSWQV1\",\n",
    "    \"model\": editModel(\"SSWQV1\", \"sswq_v1.pt\", 5),\n",
    "    \"transform\": transform_mean_std_other,\n",
    "    \"resize\": (256, 256)\n",
    "}\n",
    "\n",
    "_models = [model1, model2, model3, model4, model5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_with_models(models, plots_x, plots_y):\n",
    "    garbage_types = {0: 'glas', 1: 'organic', 2: 'paper', 3: 'restmuell', 4: 'wertstoff'}\n",
    "    if plots_x * plots_y > len(images):\n",
    "        return -1\n",
    "    random.shuffle(images)\n",
    "    fig, axis = plt.subplots(plots_x, plots_y, figsize=((plots_x+1)*5, (plots_y+4)*5))\n",
    "\n",
    "\n",
    "\n",
    "    for i, ax in enumerate(axis.flat):\n",
    "        with torch.no_grad():\n",
    "            imagePath = os.path.join(sample_images_path, images[i])\n",
    "            image = Image.open(imagePath).convert('RGB')\n",
    "            ax.imshow(image)\n",
    "            classes_predicted = []\n",
    "            probs_predicted = []\n",
    "            output_string = \"\"\n",
    "            for model in models:\n",
    "                output_string += model['name'] + ' | '\n",
    "                imagePath = os.path.join(sample_images_path, images[i])\n",
    "                image = Image.open(imagePath).convert('RGB')\n",
    "                image = image.resize(model['resize'])\n",
    "                transform = model['transform']\n",
    "                image = transform(image)\n",
    "                image = image.cuda()\n",
    "                image_tensor = image.unsqueeze_(0)\n",
    "                image_tensor.cuda()\n",
    "                output_ = model['model']((image_tensor))\n",
    "                softmax = nn.LogSoftmax(1)\n",
    "                output_ = softmax(output_)\n",
    "                output_numpy = torch.exp(output_).to('cpu').numpy()\n",
    "                output_ = output_.argmax()\n",
    "                classes_predicted.append(str(garbage_types[output_.item()]))\n",
    "                probs_predicted.append(str(round(100 * output_numpy[0][output_.item()], 0)))\n",
    "\n",
    "            output_string += '\\n'\n",
    "            for c in classes_predicted:\n",
    "                output_string += c +  ' | '\n",
    "            output_string += '\\n'\n",
    "            for p in probs_predicted:\n",
    "                output_string += p + '% | '\n",
    "            ax.set_title(output_string, fontsize=15)  # add label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#predict_with_models(_models, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = _models[4][\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(sample_dataloader)\n",
    "images, labels, path = dataiter.next()\n",
    "\n",
    "# Viewing data examples used for training\n",
    "fig, axis = plt.subplots(5, 5, figsize=(20, 20))\n",
    "with torch.no_grad():\n",
    "    for ax, image, label, path in zip(axis.flat, images, labels, path):\n",
    "        ax.grid(None)\n",
    "        ax.set_facecolor((1,1,1))\n",
    "        #ax.imshow(img_display(image))  # add image\n",
    "        ax.imshow(np.clip(img_display(image), 0, 1))  # add image\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        imagetensor = image.unsqueeze(0)\n",
    "        imagetensor.to(device)\n",
    "        output = model(imagetensor)\n",
    "        softmax = nn.LogSoftmax(1)\n",
    "        output = softmax(output)\n",
    "        outputnumpy = torch.exp(output).to('cpu').numpy()\n",
    "        output = output.argmax()\n",
    "        k = output.item() == label.item()\n",
    "        color = 'green'\n",
    "        highest_probability = str(round(100 * outputnumpy[0][output.item()], 2))\n",
    "        string = str(waste_types[output.item()]) + \"\\np = \" + highest_probability + \"%\"\n",
    "        if not k:\n",
    "            color = 'red'\n",
    "            string = str(waste_types[output.item()]) + \" (\" + str(waste_types[label.item()]) + \")\\np = \" + highest_probability + \"%\"\n",
    "        ax.set_title(string, fontsize=15, color=color)  # add label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "a = []\n",
    "b = []\n",
    "dict = {\n",
    "    'paper':[0,0,0],\n",
    "    'wertstoff':[0,0,0],\n",
    "    'restmuell':[0,0,0],\n",
    "    'glas':[0,0,0],\n",
    "    'organic':[0,0,0],\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "elapsed_time = 0\n",
    "with torch.no_grad():\n",
    "    for data_t, target_t, _ in test_dataloader:\n",
    "        target_t = target_t.type(torch.FloatTensor)\n",
    "        data_t, target_t = data_t.to(device), target_t.to(device)  # on GPU\n",
    "        for image, label in zip(data_t, target_t):\n",
    "            imagetensor = image.unsqueeze_(0)\n",
    "            imagetensor.to(device)\n",
    "            output = model(image)\n",
    "            output = output.argmax()\n",
    "            k = output.item() == label.item()\n",
    "            a.append(k)\n",
    "            b.append(waste_types[label.item()])\n",
    "            # Absolute Count\n",
    "            dict[waste_types[label.item()]][0] += 1\n",
    "            if k: # True\n",
    "                dict[waste_types[label.item()]][1] += 1\n",
    "            else: # False\n",
    "                dict[waste_types[label.item()]][2] += 1\n",
    "end_time = time.time()\n",
    "elapsed_time += end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = {\"a\":a, \"b\":b}\n",
    "df = pd.DataFrame(df)\n",
    "fig, ax1 = plt.subplots(figsize=(10, 10))\n",
    "sns.countplot(x=df['b'], hue=df['a'], ax=ax1)\n",
    "plt.savefig(\"./sswq_v1_wi\" + '/countplot.png', format='png',bbox_inches='tight', dpi=300)\n",
    "plt.savefig(\"./sswq_v1_wi\" + '/countplot.pdf', format='pdf',bbox_inches='tight', dpi=300)\n",
    "plt.savefig('./sswq_v1_wi/images_per_class_our_images.svg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(all,tp):\n",
    "    return tp/all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accs = list()\n",
    "total_acc = 0\n",
    "for label in dict:\n",
    "    accs.append(accuracy(dict[label][0],dict[label][1]))\n",
    "    total_acc += accs[-1]\n",
    "total_acc /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}