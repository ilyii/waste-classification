{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import imagesize\n",
    "from torchvision import datasets, models, transforms\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from PIL.ImageFile import ImageFile\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import matplotlib.pyplot as plt\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import time\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#vars\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "#batch_size = 128\n",
    "n_epochs = 20\n",
    "validation_split = .15\n",
    "images_for_train = 30000\n",
    "print_every = 100\n",
    "\n",
    "optimizer_name = \"Adagrad\"\n",
    "batch_size = 64\n",
    "lr = 0.001974473\n",
    "model_name = \"efficientnet_b3\"\n",
    "\n",
    "name_training = \"efficientnet_b3_training_wi\"\n",
    "os.mkdir(name_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "#data_path = \"D:\\Studium\\OneDrive - Hochschule Karlsruhe\\own-pictures\"\n",
    "\n",
    "image = []\n",
    "labels = []\n",
    "width = []\n",
    "height = []\n",
    "\n",
    "for file in os.listdir(data_path):\n",
    "    if file == 'glas':\n",
    "        for c in os.listdir(os.path.join(data_path, file)):\n",
    "            image.append(c)\n",
    "            labels.append('glas')\n",
    "            w, h = imagesize.get(data_path + \"/\" + file + \"/\" + c)\n",
    "            width.append(w), height.append(h)\n",
    "    if file == 'organic':\n",
    "        for c in os.listdir(os.path.join(data_path, file)):\n",
    "            image.append(c)\n",
    "            labels.append('organic')\n",
    "            w, h = imagesize.get(data_path + \"/\" + file + \"/\" + c)\n",
    "            width.append(w), height.append(h)\n",
    "    if file == 'paper':\n",
    "        for c in os.listdir(os.path.join(data_path, file)):\n",
    "            image.append(c)\n",
    "            labels.append('paper')\n",
    "            w, h = imagesize.get(data_path + \"/\" + file + \"/\" + c)\n",
    "            width.append(w), height.append(h)\n",
    "    if file == 'restmuell':\n",
    "        for c in os.listdir(os.path.join(data_path, file)):\n",
    "            image.append(c)\n",
    "            labels.append('restmuell')\n",
    "            w, h = imagesize.get(data_path + \"/\" + file + \"/\" + c)\n",
    "            width.append(w), height.append(h)\n",
    "    if file == 'wertstoff':\n",
    "        for c in os.listdir(os.path.join(data_path, file)):\n",
    "            image.append(c)\n",
    "            labels.append('wertstoff')\n",
    "            w, h = imagesize.get(data_path + \"/\" + file + \"/\" + c)\n",
    "            width.append(w), height.append(h)\n",
    "\n",
    "data = {'Images': image, 'labels': labels, 'width': width, 'height': height}\n",
    "data = pd.DataFrame(data)\n",
    "lb = LabelEncoder()\n",
    "data['encoded_labels'] = lb.fit_transform(data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data = data.head(images_for_train)\n",
    "tr, val = train_test_split(data, stratify=data.labels, test_size=validation_split)\n",
    "tr.reset_index(drop=True)\n",
    "val.reset_index(drop=True)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "waste_types_df = tr[['encoded_labels', 'labels']].drop_duplicates().sort_values(by='encoded_labels').reset_index(drop=True)\n",
    "garbage_types = {}\n",
    "for i in range(0, len(waste_types_df)):\n",
    "    garbage_types[i] = waste_types_df.iloc[i].labels\n",
    "print(garbage_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform_tr = transforms.Compose(\n",
    "    [transforms.Resize((300,300), interpolation= transforms.InterpolationMode.BICUBIC),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomVerticalFlip(),\n",
    "     transforms.RandomRotation(10),\n",
    "     transforms.CenterCrop(256),\n",
    "\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ])\n",
    "transform_val = transforms.Compose(\n",
    "    [transforms.Resize((256,256), interpolation= transforms.InterpolationMode.BICUBIC),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GarbageDataset(Dataset):\n",
    "    def __init__(self, img_data, img_path, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.transform = transform\n",
    "        self.img_data = img_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = os.path.join(self.img_path, self.img_data.iloc[index].labels, self.img_data.iloc[index].Images)\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        #image = image.resize((300, 300))\n",
    "        label = torch.tensor(self.img_data.iloc[index].encoded_labels)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = GarbageDataset(tr, data_path, transform_tr)\n",
    "test_dataset = GarbageDataset(val, data_path, transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def img_display(img):\n",
    "    MEAN = torch.tensor([0.485, 0.456, 0.406])\n",
    "    STD = torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "    img = img * STD[:, None, None] + MEAN[:, None, None]\n",
    "    #img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    npimg = np.transpose(npimg, (1, 2, 0))\n",
    "    return npimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    _, pred = torch.max(out, dim=1)\n",
    "    return torch.sum(pred == labels).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SSWQ_V1(nn.Module):\n",
    "    def __init__(self, num_classes, dropout=0.5, hidden_layer1=2048, hidden_layer2=2048):\n",
    "        super(SSWQ_V1, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.hidden_layer1 = hidden_layer1\n",
    "        self.hidden_layer2 = hidden_layer2\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv0 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=7, padding=1)\n",
    "\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1_3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1_4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2_3 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2_4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_4 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(512*7*7, self.hidden_layer1)\n",
    "        self.fc2 = nn.Linear(self.hidden_layer1, self.hidden_layer2)\n",
    "        self.fc3 = nn.Linear(self.hidden_layer2, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv0(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = F.relu(self.conv1_3(x))\n",
    "        #x = F.relu(self.conv1_4(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        #x = F.relu(self.conv2_3(x))\n",
    "        #x = F.relu(self.conv2_4(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        #x = F.relu(self.conv3_3(x))\n",
    "        #x = F.relu(self.conv3_4(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        #x = F.relu(self.conv4_4(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, self.dropout) #dropout was included to combat overfitting\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, self.dropout)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    if model_name == \"resnet18\":\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, len(waste_types_df))\n",
    "    elif model_name == \"alexnet\":\n",
    "        model = models.alexnet(pretrained=True)\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Linear(in_features, len(waste_types_df))\n",
    "    elif model_name == \"vgg16\":\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        in_features = model.classifier[0].in_features\n",
    "        model.classifier = nn.Linear(in_features, len(waste_types_df))\n",
    "    elif model_name == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, len(waste_types_df))\n",
    "    elif model_name == \"resnet34\":\n",
    "        model = models.resnet34(pretrained=True)\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, len(waste_types_df))\n",
    "    elif model_name == \"efficientnet_b3\":\n",
    "        model = EfficientNet.from_pretrained(\"efficientnet-b3\",num_classes=len(waste_types_df))\n",
    "    elif model_name == \"efficientnet_b4\":\n",
    "        model = EfficientNet.from_pretrained(\"efficientnet-b4\",num_classes=len(waste_types_df))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=7, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=7, pin_memory=True)\n",
    "def train_model(net, criterion, optimizer, num_epochs,step_size=7, gamma=0.1):\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    time_per_epoch = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    valid_loss_min = np.Inf\n",
    "    total_step = len(train_dataloader)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        start = time.time()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        print(f'Epoch {epoch}\\n')\n",
    "        for batch_idx, (data_, target_, _) in enumerate(train_dataloader):\n",
    "            target_ = target_.type(torch.LongTensor)\n",
    "            data_, target_ = data_.to(device, non_blocking=True), target_.to(device, non_blocking=True)\n",
    "            # zero the parameter gradients\n",
    "            for param in net.parameters():\n",
    "                param.grad = None\n",
    "            #optimizer.zero_grad()\n",
    "            outputs = net(data_)\n",
    "            loss = criterion(outputs, target_)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            _, pred = torch.max(outputs, dim=1)\n",
    "            correct += torch.sum(pred == target_).item()\n",
    "            total += target_.size(0)\n",
    "            #if batch_idx % print_every == 0:\n",
    "            #print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch, num_epochs, batch_idx, total_step, loss.item()))\n",
    "        train_acc.append(100 * correct / total)\n",
    "        train_loss.append(running_loss / total_step)\n",
    "        print(f'\\ntrain loss: {np.mean(train_loss):.4f}, train acc: {(100 * correct / total):.4f}')\n",
    "        batch_loss = 0\n",
    "        total_t = 0\n",
    "        correct_t = 0\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for data_t, target_t, _ in (test_dataloader):\n",
    "                target_t = target_t.type(torch.LongTensor)\n",
    "                data_t, target_t = data_t.to(device), target_t.to(device)  # on GPU\n",
    "                outputs_t = net(data_t)\n",
    "                loss_t = criterion(outputs_t, target_t)\n",
    "                batch_loss += loss_t.item()\n",
    "                _, pred_t = torch.max(outputs_t, dim=1)\n",
    "                correct_t += torch.sum(pred_t == target_t).item()\n",
    "                total_t += target_t.size(0)\n",
    "            val_acc.append(100 * correct_t / total_t)\n",
    "            val_loss.append(batch_loss / len(test_dataloader))\n",
    "            network_learned = batch_loss < valid_loss_min\n",
    "            print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t / total_t):.4f}\\n')\n",
    "            # Saving the best weight\n",
    "            if network_learned:\n",
    "                valid_loss_min = batch_loss\n",
    "                torch.save(net.state_dict(), name_training + '/model.pt')\n",
    "                print('Detected network improvement, saving current model')\n",
    "\n",
    "        net.train()\n",
    "        exp_lr_scheduler.step()\n",
    "        end = time.time()\n",
    "        time_per_epoch.append(round((end-start),2))\n",
    "        print(\"Time for this epoch: \" + str(round((end-start),2)) + \"s\")\n",
    "    return val_loss, val_acc, train_loss, train_acc, time_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get pretrained model\n",
    "model = get_model(model_name)\n",
    "#model = SSWQ_V1(len(waste_types_df), dropout=0.5, \n",
    "                #hidden_layer1=512, hidden_layer2=2048)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Configure optimizer\n",
    "optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "# Train a model\n",
    "val_loss,val_acc, train_loss, train_acc, time_per_epoch = train_model(model, criterion, optimizer, num_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig_loss = plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Train - Validation Loss\")\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(val_loss, label='validation')\n",
    "plt.xlabel('num_epochs', fontsize=12)\n",
    "plt.ylabel('loss', fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(name_training + '/loss.png', format='png',bbox_inches='tight')\n",
    "plt.savefig(name_training + '/loss.pdf', format='pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig_accuracy = plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Train - Validation Accuracy\")\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(val_acc, label='validation')\n",
    "plt.xlabel('num_epochs', fontsize=12)\n",
    "plt.ylabel('accuracy', fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(name_training + '/accuracy.png', format='png',bbox_inches='tight')\n",
    "plt.savefig(name_training + '/accuracy.pdf', format='pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#net = SSWQ_V1(len(waste_types_df), dropout=0.5, \n",
    "                #hidden_layer1=512, hidden_layer2=2048)\n",
    "#net = models.resnet34(pretrained=False)\n",
    "net = EfficientNet.from_pretrained(\"efficientnet-b3\",num_classes=len(waste_types_df))\n",
    "#in_features = net.fc.in_features\n",
    "#net.fc = nn.Linear(in_features, len(waste_types_df))\n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load(name_training + '/model.pt'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(test_dataloader)\n",
    "images, labels, path = dataiter.next()\n",
    "\n",
    "# Viewing data examples used for training\n",
    "fig, axis = plt.subplots(3, 5, figsize=(15, 11))\n",
    "with torch.no_grad():\n",
    "    for ax, image, label, path in zip(axis.flat, images, labels, path):\n",
    "        ax.grid(None)\n",
    "        ax.set_facecolor((1,1,1))\n",
    "        ax.imshow(img_display(image))  # add image\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        imagetensor = image.unsqueeze(0)\n",
    "        imagetensor.to(device)\n",
    "        output = net(imagetensor)\n",
    "        softmax = nn.LogSoftmax(1)\n",
    "        output = softmax(output)\n",
    "        outputnumpy = torch.exp(output).to('cpu').numpy()\n",
    "        output = output.argmax()\n",
    "        k = output.item() == label.item()\n",
    "        color = 'green'\n",
    "        highest_probability = str(round(100 * outputnumpy[0][output.item()], 2))\n",
    "        string = str(garbage_types[output.item()]) + \"\\np = \" + highest_probability + \"%\"\n",
    "        if not k:\n",
    "            color = 'red'\n",
    "            string = str(garbage_types[output.item()]) + \" (\" + str(garbage_types[label.item()]) + \")\\np = \" + highest_probability + \"%\"\n",
    "        ax.set_title(string, fontsize=15, color=color)  # add label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = []\n",
    "b = []\n",
    "dict = {\n",
    "    'paper':[0,0,0],\n",
    "    'wertstoff':[0,0,0],\n",
    "    'restmuell':[0,0,0],\n",
    "    'glas':[0,0,0],\n",
    "    'organic':[0,0,0],\n",
    "}\n",
    "with torch.no_grad():\n",
    "    for data_t, target_t, _ in test_dataloader:\n",
    "        target_t = target_t.type(torch.FloatTensor)\n",
    "        data_t, target_t = data_t.to(device), target_t.to(device)  # on GPU\n",
    "        for image, label in zip(data_t, target_t):\n",
    "            imagetensor = image.unsqueeze_(0)\n",
    "            imagetensor.to(device)\n",
    "            output = net(image)\n",
    "            output = output.argmax()\n",
    "            k = output.item() == label.item()\n",
    "            a.append(k)\n",
    "            b.append(garbage_types[label.item()])\n",
    "            # Absolute Count\n",
    "            dict[garbage_types[label.item()]][0] += 1\n",
    "            if k: # True\n",
    "                dict[garbage_types[label.item()]][1] += 1\n",
    "            else: # False\n",
    "                dict[garbage_types[label.item()]][2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = {\"a\":a, \"b\":b}\n",
    "df = pd.DataFrame(df)\n",
    "fig, ax1 = plt.subplots(figsize=(10, 10))\n",
    "sns.countplot(x=df['b'], hue=df['a'], ax=ax1)\n",
    "plt.savefig(name_training + '/countplot.png', format='png',bbox_inches='tight')\n",
    "plt.savefig(name_training + '/countplot.pdf', format='pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig_time = plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Time per epoch\")\n",
    "plt.plot(time_per_epoch, label='time')\n",
    "plt.xlabel('num_epochs', fontsize=12)\n",
    "plt.ylabel('time in s', fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(name_training + '/fig_time.png', format='png',bbox_inches='tight')\n",
    "plt.savefig(name_training + '/fig_time.pdf', format='pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for time in time_per_epoch:\n",
    "     sum += time\n",
    "\n",
    "avg_time = sum / len(time_per_epoch)\n",
    "print(avg_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}